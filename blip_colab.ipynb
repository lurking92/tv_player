{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "18f3c9f9",
      "metadata": {
        "id": "18f3c9f9"
      },
      "source": [
        "本 Notebook 在 Google Colab 上可直接執行，完成以下工作：\n",
        "- 安裝相依套件並建立專案目錄\n",
        "- 自動下載 Grounding DINO 所需權重\n",
        "- 影片上傳到 `data/videos/`\n",
        "- 以 `scripts/` 拆分模組：`extract_frames.py`、`object_detector.py`、`generate_caption.py`\n",
        "- 透過 `main.py` 串起整個流程，輸出字幕與偵測摘要\n",
        "\n",
        "執行順序：依序執行每個區塊即可；最後用 `!python main.py --video ...` 或 `--dir ...` 執行。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e2d5985",
      "metadata": {
        "id": "0e2d5985"
      },
      "source": [
        "## 函式庫安裝與設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d4e64f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6d4e64f",
        "outputId": "111f66ff-2d33-4924-c105-f0c98f0a13f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "opencc-python-reimplemented\n",
        "opencv-python-headless>=4.10.0.84\n",
        "torch\n",
        "torchvision\n",
        "transformers>=4.41.0\n",
        "tokenizers>=0.20.0\n",
        "accelerate>=0.24.1\n",
        "Pillow>=10.0.0\n",
        "tqdm\n",
        "ffmpeg-python\n",
        "sentencepiece\n",
        "sacremoses\n",
        "scipy>=1.14.0\n",
        "numpy>=1.26.4,<2.0\n",
        "einops\n",
        "requests\n",
        "timm>=0.9.16\n",
        "protobuf>=4.25.3,<5\n",
        "matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77bcc6d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77bcc6d9",
        "outputId": "2a0eff74-344d-415b-cff2-648d2511ecd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m函式庫安裝完成。\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -r requirements.txt\n",
        "print(\"函式庫安裝完成。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ddeb170",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ddeb170",
        "outputId": "19db65f6-3889-4b6a-c4b5-a9dd7ef4ed23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "目錄準備完成。\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path('/content')\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "VIDEO_DIR = DATA_DIR / 'videos'\n",
        "FRAME_DIR = DATA_DIR / 'frames'\n",
        "OUTPUT_DIR = Path('outputs')\n",
        "MODELS_DIR = Path('models')\n",
        "SCRIPTS_DIR = Path('scripts')\n",
        "\n",
        "for folder in [DATA_DIR, VIDEO_DIR, FRAME_DIR, OUTPUT_DIR, MODELS_DIR, SCRIPTS_DIR]:\n",
        "    folder.mkdir(parents=True, exist_ok=True)\n",
        "print('目錄準備完成。')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32d98d2f",
      "metadata": {
        "id": "32d98d2f"
      },
      "source": [
        "## 模型下載與設定（Grounding DINO）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b65526e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b65526e",
        "outputId": "67db88e4-b927-4469-b3c2-6bcdcf82818c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GroundingDINO_SwinT_OGC.py: 1.01kB [00:00, 1.65MB/s]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "已下載 GroundingDINO_SwinT_OGC.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "groundingdino_swint_ogc.pth: 100%|██████████| 694M/694M [00:13<00:00, 52.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "已下載 groundingdino_swint_ogc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "GROUNDING_DINO_CONFIG_URL = 'https://raw.githubusercontent.com/IDEA-Research/GroundingDINO/main/groundingdino/config/GroundingDINO_SwinT_OGC.py'\n",
        "GROUNDING_DINO_WEIGHTS_URL = 'https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth'\n",
        "\n",
        "config_path = Path('models/GroundingDINO_SwinT_OGC.py')\n",
        "weights_path = Path('models/groundingdino_swint_ogc.pth')\n",
        "\n",
        "def download_file(url: str, destination: Path) -> None:\n",
        "    if destination.exists():\n",
        "        print(f'{destination.name} 已存在，略過下載。')\n",
        "        return\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "    total = int(response.headers.get('content-length', 0))\n",
        "    progress = tqdm(total=total, unit='B', unit_scale=True, desc=destination.name)\n",
        "    with destination.open('wb') as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "                progress.update(len(chunk))\n",
        "    progress.close()\n",
        "    print(f'已下載 {destination.name}')\n",
        "\n",
        "download_file(GROUNDING_DINO_CONFIG_URL, config_path)\n",
        "download_file(GROUNDING_DINO_WEIGHTS_URL, weights_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ccc1fed",
      "metadata": {
        "id": "7ccc1fed"
      },
      "source": [
        "### 選用：掛載 Google Drive（若影片放在雲端硬碟）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ae6effd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ae6effd",
        "outputId": "72411f93-84d4-4622-de54-da9fbe9aeab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 如需使用 Google Drive 檔案請執行，否則可略過\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0e4421a",
      "metadata": {
        "id": "e0e4421a"
      },
      "source": [
        "### 選用：Hugging Face 登入（若需存取 gated 模型）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66306c2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66306c2b",
        "outputId": "74437792-6355-4a00-b933-b311d1070d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face 登入成功\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "try:\n",
        "    # Colab 的使用者可於右上角「變數」區設定 HF_TOKEN\n",
        "    from google.colab import userdata\n",
        "    token = userdata.get('HF_TOKEN')\n",
        "except Exception:\n",
        "    token = None\n",
        "\n",
        "if token:\n",
        "    login(token)\n",
        "    print(\"Hugging Face 登入成功\")\n",
        "else:\n",
        "    print(\"未提供 HF_TOKEN，若模型需要授權請手動登入或設定變數。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbab785b",
      "metadata": {
        "id": "bbab785b"
      },
      "source": [
        "## 上傳測試影片到 `data/videos/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91d1f9f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "91d1f9f4",
        "outputId": "73975c39-ac47-46f5-ef5a-6b27fafa0cc5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73b1c88a-2621-4826-b48d-11723a19b716\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-73b1c88a-2621-4826-b48d-11723a19b716\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Cook carrot1_1.mp4 to Cook carrot1_1.mp4\n",
            "Saving Cook fried bread4_1.mp4 to Cook fried bread4_1.mp4\n",
            "Saving Cook potato using microwave1_4.mp4 to Cook potato using microwave1_4.mp4\n",
            "影片已上傳到: ['/content/data/videos/Cook carrot1_1.mp4', '/content/data/videos/Cook fried bread4_1.mp4', '/content/data/videos/Cook potato using microwave1_4.mp4']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "uploaded = files.upload()\n",
        "video_paths = []\n",
        "for fname in uploaded.keys():\n",
        "    dst = VIDEO_DIR / fname\n",
        "    shutil.move(fname, dst)\n",
        "    video_paths.append(str(dst))\n",
        "print('影片已上傳到:', video_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ba2d3a4",
      "metadata": {
        "id": "2ba2d3a4"
      },
      "source": [
        "## 影格提取模組：`scripts/extract_frames.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c101c242",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c101c242",
        "outputId": "eef49f3e-5328-4ef7-e567-c1dc2b5eab65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scripts/extract_frames.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile scripts/extract_frames.py\n",
        "import os\n",
        "from typing import List, Tuple\n",
        "import cv2\n",
        "\n",
        "def extract_frames(video_path: str, output_dir: str, target_fps: float = 1.0) -> Tuple[List[Tuple[str, float]], float]:\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f'無法開啟影片: {video_path}')\n",
        "\n",
        "    native_fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "    step = max(int(round(native_fps / max(target_fps, 1e-3))), 1)\n",
        "\n",
        "    frame_idx = 0\n",
        "    saved: List[Tuple[str, float]] = []\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if frame_idx % step == 0:\n",
        "            timestamp = frame_idx / native_fps\n",
        "            frame_name = f'frame_{frame_idx:06d}.jpg'\n",
        "            frame_path = os.path.join(output_dir, frame_name)\n",
        "            cv2.imwrite(frame_path, frame)\n",
        "            saved.append((frame_path, timestamp))\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f'已提取 {len(saved)} 個影格，原始FPS: {native_fps:.2f}')\n",
        "    return saved, native_fps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45d2ed66",
      "metadata": {
        "id": "45d2ed66"
      },
      "source": [
        "## 物件偵測模組：`scripts/object_detector.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4101731b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4101731b",
        "outputId": "e31c487b-efe1-474e-ce3b-7ef370be242e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scripts/object_detector.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile scripts/object_detector.py\n",
        "from __future__ import annotations\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import torch\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
        "\n",
        "# 詳細的物件提示詞，涵蓋居家環境中的重要物件\n",
        "DEFAULT_PROMPT = (\n",
        "    'person, man, woman, child, elderly, baby, '\n",
        "    'bed, pillow, blanket, sheet, mattress, nightstand, bedside table, '\n",
        "    'lamp, desk lamp, floor lamp, ceiling light, '\n",
        "    'sofa, couch, armchair, chair, dining chair, office chair, '\n",
        "    'table, dining table, coffee table, desk, '\n",
        "    'television, tv, monitor, computer, laptop, '\n",
        "    'stove, oven, refrigerator, fridge, microwave, '\n",
        "    'sink, faucet, cabinet, cupboard, drawer, '\n",
        "    'pan, pot, bowl, cup, plate, knife, fork, spoon, '\n",
        "    'toilet, bathtub, shower, mirror, towel, '\n",
        "    'door, window, curtain, blind, '\n",
        "    'carpet, rug, floor, wall, ceiling, '\n",
        "    'plant, flower, book, clock, picture, painting'\n",
        ")\n",
        "\n",
        "_processor: Optional[AutoProcessor] = None\n",
        "_model: Optional[AutoModelForZeroShotObjectDetection] = None\n",
        "_device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def setup_grounding_dino() -> None:\n",
        "    \"\"\"初始化 Grounding DINO 模型\"\"\"\n",
        "    global _processor, _model\n",
        "    if _processor is not None and _model is not None:\n",
        "        print('Grounding DINO 模型已載入')\n",
        "        return\n",
        "\n",
        "    print('正在載入 Grounding DINO 模型...')\n",
        "    model_name = \"IDEA-Research/grounding-dino-tiny\"\n",
        "    _processor = AutoProcessor.from_pretrained(model_name)\n",
        "    _model = AutoModelForZeroShotObjectDetection.from_pretrained(model_name)\n",
        "    _model.to(_device)\n",
        "    print(f'Grounding DINO 模型已載入至 {_device}')\n",
        "\n",
        "def detect_objects(\n",
        "    image_path: str,\n",
        "    text_prompt: str = DEFAULT_PROMPT,\n",
        "    box_threshold: float = 0.25,\n",
        "    top_k: int = 15,\n",
        "    visualize: bool = False\n",
        ") -> Tuple[List[Dict], Optional[Image.Image]]:\n",
        "    \"\"\"使用 Grounding DINO 進行物件偵測\n",
        "\n",
        "    Args:\n",
        "        image_path: 圖像路徑\n",
        "        text_prompt: 物件描述提示\n",
        "        box_threshold: 信心度閾值\n",
        "        top_k: 最多返回物件數量\n",
        "        visualize: 是否生成可視化圖像\n",
        "\n",
        "    Returns:\n",
        "        (偵測結果列表, 可視化圖像)\n",
        "    \"\"\"\n",
        "    if _processor is None or _model is None:\n",
        "        raise RuntimeError('請先呼叫 setup_grounding_dino() 載入模型。')\n",
        "\n",
        "    # 載入圖像\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # 準備輸入\n",
        "    inputs = _processor(images=image, text=text_prompt, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(_device) for k, v in inputs.items()}\n",
        "\n",
        "    # 執行推理\n",
        "    with torch.no_grad():\n",
        "        outputs = _model(**inputs)\n",
        "\n",
        "    # 後處理結果\n",
        "    target_sizes = torch.tensor([image.size[::-1]]).to(_device)  # [height, width]\n",
        "    results = _processor.post_process_grounded_object_detection(\n",
        "        outputs, target_sizes=target_sizes, threshold=box_threshold\n",
        "    )[0]\n",
        "\n",
        "    # 整理偵測結果\n",
        "    detections: List[Dict] = []\n",
        "    if 'boxes' in results:\n",
        "        boxes = results['boxes'].cpu()\n",
        "        scores = results['scores'].cpu()\n",
        "        labels = results['labels']\n",
        "\n",
        "        for box, score, label in zip(boxes, scores, labels):\n",
        "            x1, y1, x2, y2 = box.tolist()\n",
        "            detections.append({\n",
        "                'label': label.lower(),\n",
        "                'score': float(score),\n",
        "                'bbox_xyxy': [x1, y1, x2, y2],\n",
        "                'area': (x2 - x1) * (y2 - y1)\n",
        "            })\n",
        "\n",
        "    # 依信心度排序並限制數量\n",
        "    detections = sorted(detections, key=lambda d: d['score'], reverse=True)[:top_k]\n",
        "\n",
        "    # 生成可視化\n",
        "    annotated_image = None\n",
        "    if visualize and detections:\n",
        "        annotated_image = create_detection_visualization(image, detections)\n",
        "\n",
        "    return detections, annotated_image\n",
        "\n",
        "def create_detection_visualization(image: Image.Image, detections: List[Dict]) -> Image.Image:\n",
        "    \"\"\"創建偵測結果可視化圖像\"\"\"\n",
        "    vis_image = image.copy()\n",
        "    draw = ImageDraw.Draw(vis_image)\n",
        "\n",
        "    # 顏色池\n",
        "    colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
        "\n",
        "    try:\n",
        "        font = ImageFont.truetype('/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', 16)\n",
        "    except Exception:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    for i, detection in enumerate(detections[:10]):  # 最多顯示10個\n",
        "        x1, y1, x2, y2 = detection['bbox_xyxy']\n",
        "        color = colors[i % len(colors)]\n",
        "\n",
        "        # 邊界框\n",
        "        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)\n",
        "\n",
        "        # 標籤\n",
        "        label_text = f\"{detection['label']} ({detection['score']:.2f})\"\n",
        "        text_bbox = draw.textbbox((x1, y1-25), label_text, font=font)\n",
        "        draw.rectangle(text_bbox, fill=color)\n",
        "        draw.text((x1, y1-25), label_text, fill='white', font=font)\n",
        "\n",
        "    return vis_image\n",
        "\n",
        "def summarize_detections(detections: List[Dict], top_k: int = 8) -> str:\n",
        "    \"\"\"總結偵測結果為簡潔文字\"\"\"\n",
        "    if not detections:\n",
        "        return '未偵測到重點物件'\n",
        "\n",
        "    # 過濾重複標籤，保留最高信心度的\n",
        "    unique_detections = {}\n",
        "    for det in detections:\n",
        "        label = det['label']\n",
        "        if label not in unique_detections or det['score'] > unique_detections[label]['score']:\n",
        "            unique_detections[label] = det\n",
        "\n",
        "    # 依信心度排序\n",
        "    sorted_dets = sorted(unique_detections.values(), key=lambda d: d['score'], reverse=True)\n",
        "    items = [f\"{d['label']}({d['score']:.2f})\" for d in sorted_dets[:top_k]]\n",
        "\n",
        "    return ', '.join(items)\n",
        "\n",
        "def analyze_scene_context(detections: List[Dict]) -> Dict[str, any]:\n",
        "    \"\"\"分析場景上下文資訊\"\"\"\n",
        "    context = {\n",
        "        'person_count': 0,\n",
        "        'furniture_items': [],\n",
        "        'appliances': [],\n",
        "        'room_indicators': [],\n",
        "        'dominant_objects': []\n",
        "    }\n",
        "\n",
        "    for det in detections:\n",
        "        label = det['label'].lower()\n",
        "        score = det['score']\n",
        "\n",
        "        # 統計人數\n",
        "        if any(person_word in label for person_word in ['person', 'man', 'woman', 'child', 'people']):\n",
        "            context['person_count'] += 1\n",
        "\n",
        "        # 分類家具\n",
        "        furniture_keywords = ['sofa', 'chair', 'table', 'bed', 'desk', 'cabinet']\n",
        "        if any(keyword in label for keyword in furniture_keywords):\n",
        "            context['furniture_items'].append((label, score))\n",
        "\n",
        "        # 分類電器\n",
        "        appliance_keywords = ['tv', 'television', 'refrigerator', 'microwave', 'oven', 'stove']\n",
        "        if any(keyword in label for keyword in appliance_keywords):\n",
        "            context['appliances'].append((label, score))\n",
        "\n",
        "        # 房間指示器（只納入較高信心度）\n",
        "        if score > 0.3:\n",
        "            context['room_indicators'].append((label, score))\n",
        "\n",
        "    # 主導物件（大面積且高信心度）\n",
        "    for det in detections[:5]:\n",
        "        if det['score'] > 0.4 and det.get('area', 0) > 1000:\n",
        "            context['dominant_objects'].append((det['label'], det['score']))\n",
        "\n",
        "    return context\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fad966a",
      "metadata": {
        "id": "9fad966a"
      },
      "source": [
        "## 文字敘述模組：`scripts/generate_caption.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26e938c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26e938c6",
        "outputId": "26217bf9-6056-475e-ec92-0c4a6931b469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scripts/generate_caption.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile scripts/generate_caption.py\n",
        "from __future__ import annotations\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration, pipeline\n",
        "from opencc import OpenCC\n",
        "\n",
        "# 全局變數\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "_blip_processor = None\n",
        "_blip_model = None\n",
        "_translator = None\n",
        "_converter = None\n",
        "\n",
        "def initialize_models():\n",
        "    \"\"\"初始化所有必要的模型\"\"\"\n",
        "    global _blip_processor, _blip_model, _translator, _converter\n",
        "\n",
        "    if _blip_processor is None:\n",
        "        print('正在載入 BLIP 模型...')\n",
        "        _blip_processor = BlipProcessor.from_pretrained('Salesforce/blip-image-captioning-large')\n",
        "        _blip_model = BlipForConditionalGeneration.from_pretrained('Salesforce/blip-image-captioning-large').to(DEVICE)\n",
        "        print(f'BLIP 模型已載入至 {DEVICE}')\n",
        "\n",
        "    if _translator is None:\n",
        "        print('正在載入翻譯模型...')\n",
        "        _translator = pipeline('translation', model='Helsinki-NLP/opus-mt-en-zh', device=0 if torch.cuda.is_available() else -1)\n",
        "        print('翻譯模型已載入')\n",
        "\n",
        "    if _converter is None:\n",
        "        _converter = OpenCC('s2t')\n",
        "\n",
        "# 物件中英對照表\n",
        "OBJECT_TRANSLATIONS = {\n",
        "    'person': '人物', 'people': '人', 'man': '男性', 'woman': '女性', 'child': '兒童', 'baby': '嬰兒',\n",
        "    'bed': '床鋪', 'pillow': '枕頭', 'blanket': '毛毯', 'sheet': '床單', 'mattress': '床墊',\n",
        "    'nightstand': '床頭櫃', 'bedside table': '床邊桌',\n",
        "    'lamp': '檯燈', 'desk lamp': '桌燈', 'floor lamp': '立燈', 'ceiling light': '天花板燈',\n",
        "    'sofa': '沙發', 'couch': '沙發', 'armchair': '扶手椅', 'chair': '椅子',\n",
        "    'dining chair': '餐椅', 'office chair': '辦公椅',\n",
        "    'table': '桌子', 'dining table': '餐桌', 'coffee table': '茶几', 'desk': '書桌',\n",
        "    'television': '電視', 'tv': '電視', 'monitor': '螢幕', 'computer': '電腦', 'laptop': '筆電',\n",
        "    'stove': '爐子', 'oven': '烤箱', 'refrigerator': '冰箱', 'fridge': '冰箱', 'microwave': '微波爐',\n",
        "    'sink': '水槽', 'faucet': '水龍頭', 'cabinet': '櫥櫃', 'cupboard': '櫃子', 'drawer': '抽屜',\n",
        "    'pan': '平底鍋', 'pot': '湯鍋', 'bowl': '碗', 'cup': '杯子', 'plate': '盤子',\n",
        "    'knife': '刀具', 'fork': '叉子', 'spoon': '湯匙',\n",
        "    'toilet': '馬桶', 'bathtub': '浴缸', 'shower': '淋浴設備', 'mirror': '鏡子', 'towel': '毛巾',\n",
        "    'door': '門', 'window': '窗戶', 'curtain': '窗簾', 'blind': '百葉窗',\n",
        "    'carpet': '地毯', 'rug': '地墊', 'floor': '地板', 'wall': '牆壁', 'ceiling': '天花板',\n",
        "    'plant': '植物', 'flower': '花朵', 'book': '書籍', 'clock': '時鐘', 'picture': '圖畫', 'painting': '畫作'\n",
        "}\n",
        "\n",
        "# 房間關鍵物件映射\n",
        "ROOM_KEYWORDS = {\n",
        "    '臥室': {'bed', 'pillow', 'blanket', 'nightstand', 'bedside table', 'mattress', 'sheet'},\n",
        "    '廚房': {'stove', 'oven', 'refrigerator', 'fridge', 'microwave', 'sink', 'cabinet', 'pan', 'pot', 'bowl', 'cup', 'plate'},\n",
        "    '廁所': {'toilet', 'bathtub', 'shower', 'sink', 'mirror', 'towel', 'faucet'},\n",
        "    '客廳': {'sofa', 'couch', 'television', 'tv', 'coffee table', 'armchair', 'carpet', 'rug'}\n",
        "}\n",
        "\n",
        "# 環境描述模板\n",
        "ENVIRONMENT_TEMPLATES = {\n",
        "    '臥室': ['溫馨的睡眠空間', '私人休息區域', '舒適的臥房環境'],\n",
        "    '廚房': ['烹飪與用餐空間', '家庭料理區域', '廚房工作環境'],\n",
        "    '廁所': ['衛浴清潔空間', '個人盥洗區域', '浴室環境'],\n",
        "    '客廳': ['家庭聚會空間', '休閒娛樂區域', '客廳起居環境']\n",
        "}\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_base_caption(image_path: str, prompt: str = None) -> str:\n",
        "    \"\"\"使用 BLIP 生成基礎英文描述\"\"\"\n",
        "    if _blip_processor is None or _blip_model is None:\n",
        "        raise RuntimeError('請先呼叫 initialize_models() 載入模型')\n",
        "\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    if prompt is None:\n",
        "        prompt = \"Describe this scene in detail, including the people, objects, activities, and environment.\"\n",
        "\n",
        "    inputs = _blip_processor(images=image, text=prompt, return_tensors='pt').to(DEVICE)\n",
        "\n",
        "    output = _blip_model.generate(\n",
        "        **inputs,\n",
        "        max_length=120,\n",
        "        num_beams=8,\n",
        "        no_repeat_ngram_size=3,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        length_penalty=1.2\n",
        "    )\n",
        "\n",
        "    caption = _blip_processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    if prompt and caption.startswith(prompt):\n",
        "        caption = caption[len(prompt):].strip()\n",
        "\n",
        "    return caption\n",
        "\n",
        "def translate_to_traditional_chinese(text: str) -> str:\n",
        "    \"\"\"將英文翻譯為繁體中文\"\"\"\n",
        "    if _translator is None or _converter is None:\n",
        "        raise RuntimeError('請先呼叫 initialize_models() 載入模型')\n",
        "\n",
        "    try:\n",
        "        sentences = text.split('. ')\n",
        "        translated_sentences = []\n",
        "        for sentence in sentences:\n",
        "            if sentence.strip():\n",
        "                result = _translator(sentence.strip())[0]['translation_text']\n",
        "                translated_sentences.append(result)\n",
        "        translated_text = '。'.join(translated_sentences)\n",
        "        if not translated_text.endswith('。'):\n",
        "            translated_text += '。'\n",
        "        return _converter.convert(translated_text)\n",
        "    except Exception as e:\n",
        "        print(f'翻譯過程中出現錯誤: {e}')\n",
        "        return '無法生成中文描述。'\n",
        "\n",
        "def infer_room_from_detections(detections: List[Dict]) -> Optional[str]:\n",
        "    \"\"\"從偵測結果推斷房間類型\"\"\"\n",
        "    if not detections:\n",
        "        return None\n",
        "    labels = {d['label'].lower() for d in detections if d['score'] > 0.3}\n",
        "    room_scores = {}\n",
        "    for room, keywords in ROOM_KEYWORDS.items():\n",
        "        score = len(labels & keywords)\n",
        "        if score > 0:\n",
        "            room_scores[room] = score\n",
        "    if room_scores:\n",
        "        return max(room_scores, key=room_scores.get)\n",
        "    return None\n",
        "\n",
        "def create_object_description(detections: List[Dict], max_objects: int = 10) -> str:\n",
        "    \"\"\"創建詳細的物件描述\"\"\"\n",
        "    if not detections:\n",
        "        return \"\"\n",
        "    people, furniture, appliances, other_objects = [], [], [], []\n",
        "    for det in detections[:max_objects]:\n",
        "        label = det['label'].lower()\n",
        "        score = det['score']\n",
        "        zh_label = OBJECT_TRANSLATIONS.get(label, label)\n",
        "        obj_desc = f\"{zh_label}(信心度{score:.2f})\"\n",
        "        if any(w in label for w in ['person', 'man', 'woman', 'child', 'people', 'baby']):\n",
        "            people.append(obj_desc)\n",
        "        elif any(w in label for w in ['sofa', 'chair', 'table', 'bed', 'desk', 'cabinet']):\n",
        "            furniture.append(obj_desc)\n",
        "        elif any(w in label for w in ['tv', 'television', 'refrigerator', 'microwave', 'oven', 'stove']):\n",
        "            appliances.append(obj_desc)\n",
        "        else:\n",
        "            other_objects.append(obj_desc)\n",
        "    descriptions = []\n",
        "    if people:\n",
        "        descriptions.append(f\"人物：{', '.join(people)}\")\n",
        "    if furniture:\n",
        "        descriptions.append(f\"家具：{', '.join(furniture[:5])}\")\n",
        "    if appliances:\n",
        "        descriptions.append(f\"電器：{', '.join(appliances[:3])}\")\n",
        "    if other_objects:\n",
        "        descriptions.append(f\"其他物件：{', '.join(other_objects[:5])}\")\n",
        "    return '；'.join(descriptions) + '。' if descriptions else \"\"\n",
        "\n",
        "def analyze_spatial_relationships(detections: List[Dict]) -> str:\n",
        "    \"\"\"分析空間關係\"\"\"\n",
        "    if len(detections) < 2:\n",
        "        return \"\"\n",
        "    relationships = []\n",
        "    people = [d for d in detections if any(w in d['label'].lower() for w in ['person', 'man', 'woman', 'child'])]\n",
        "    furniture = [d for d in detections if any(w in d['label'].lower() for w in ['sofa', 'chair', 'bed', 'table'])]\n",
        "    if people and furniture:\n",
        "        relationships.append(\"場景中有人物與家具的互動配置\")\n",
        "    if len(detections) > 8:\n",
        "        relationships.append(\"空間中物件配置豐富\")\n",
        "    elif len(detections) > 4:\n",
        "        relationships.append(\"空間中有適度的物件配置\")\n",
        "    return '；'.join(relationships) + '。' if relationships else \"\"\n",
        "\n",
        "def generate_enhanced_caption(\n",
        "    image_path: str,\n",
        "    detections: List[Dict],\n",
        "    room_hint: Optional[str] = None,\n",
        "    knowledge_items: Optional[List[str]] = None,\n",
        "    *,\n",
        "    include_objects: bool = True,\n",
        "    include_spatial: bool = True,\n",
        "    include_room: bool = True,\n",
        "    include_knowledge: bool = True,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    生成詳細描述；可用開關控制是否拼接「物件摘要/空間關係/房間推斷/知識補充」。\n",
        "    若要「只要敘述」，把四個 include_* 都設為 False。\n",
        "    \"\"\"\n",
        "    initialize_models()\n",
        "\n",
        "    # 生成多個不同角度的基礎描述\n",
        "    base_captions = []\n",
        "    prompts = [\n",
        "        \"Describe this indoor scene in detail, focusing on the people, furniture, and activities.\",\n",
        "        \"What is happening in this room? Describe the environment, objects, and any people present.\",\n",
        "        \"Provide a comprehensive description of this indoor space, including all visible elements.\"\n",
        "    ]\n",
        "    for prompt in prompts[:2]:\n",
        "        try:\n",
        "            cap = generate_base_caption(image_path, prompt)\n",
        "            if cap and len(cap) > 10:\n",
        "                base_captions.append(cap)\n",
        "        except Exception as e:\n",
        "            print(f\"生成描述時出錯: {e}\")\n",
        "            continue\n",
        "    if not base_captions:\n",
        "        base_captions = [generate_base_caption(image_path)]\n",
        "    primary_caption = max(base_captions, key=len) if base_captions else \"Indoor scene\"\n",
        "\n",
        "    # 翻譯為中文（純敘述基底）\n",
        "    zh_caption = translate_to_traditional_chinese(primary_caption)\n",
        "    description_parts = [zh_caption]  # 基底：只敘述\n",
        "\n",
        "    # 依開關決定是否附加其他說明\n",
        "    if include_objects:\n",
        "        object_desc = create_object_description(detections)\n",
        "        if object_desc:\n",
        "            description_parts.append(f\"偵測到的主要物件包括：{object_desc}\")\n",
        "    if include_spatial:\n",
        "        spatial_desc = analyze_spatial_relationships(detections)\n",
        "        if spatial_desc:\n",
        "            description_parts.append(f\"空間配置特徵：{spatial_desc}\")\n",
        "    if include_room and room_hint:\n",
        "        env_templates = ENVIRONMENT_TEMPLATES.get(room_hint, [f'{room_hint}環境'])\n",
        "        env_desc = env_templates[0] if env_templates else f'{room_hint}環境'\n",
        "        description_parts.append(f\"場景分析：此為{env_desc}。\")\n",
        "    if include_knowledge and knowledge_items:\n",
        "        kg_desc = '；'.join(knowledge_items)\n",
        "        description_parts.append(f\"知識圖譜補充：{kg_desc}。\")\n",
        "\n",
        "    final_description = ' '.join(description_parts)\n",
        "    if not final_description.endswith('。'):\n",
        "        final_description += '。'\n",
        "    return final_description\n",
        "\n",
        "def augment_with_knowledge_graph(caption: str, detections: List[Dict], knowledge_items: Optional[List[str]] = None) -> str:\n",
        "    \"\"\"預留與知識圖譜整合的接口\"\"\"\n",
        "    if not knowledge_items:\n",
        "        return caption\n",
        "    extra_knowledge = '；'.join(knowledge_items)\n",
        "    return f\"{caption} 知識圖譜增強：{extra_knowledge}。\"\n",
        "\n",
        "__all__ = [\n",
        "    'initialize_models',\n",
        "    'generate_enhanced_caption',\n",
        "    'infer_room_from_detections',\n",
        "    'augment_with_knowledge_graph'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d549bdad",
      "metadata": {
        "id": "d549bdad"
      },
      "source": [
        "## 工具模組：`scripts/utils.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f99e64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5f99e64",
        "outputId": "2866b263-153d-4156-8921-757fe0214347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting scripts/utils.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile scripts/utils.py\n",
        "from __future__ import annotations\n",
        "from typing import List, Dict, Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "def ensure_dir(path: Path) -> Path:\n",
        "    path = Path(path)\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "    return path\n",
        "\n",
        "def save_txt(lines: List[str], filepath: Path) -> None:\n",
        "    filepath = Path(filepath)\n",
        "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with filepath.open('w', encoding='utf-8') as f:\n",
        "        for line in lines:\n",
        "            f.write(str(line).rstrip() + '\\n')\n",
        "\n",
        "def format_timestamp(seconds: float) -> str:\n",
        "    seconds = int(seconds)\n",
        "    h = seconds // 3600\n",
        "    m = (seconds % 3600) // 60\n",
        "    s = seconds % 60\n",
        "    if h > 0:\n",
        "        return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "    return f\"{m:02d}:{s:02d}\"\n",
        "\n",
        "def format_detection_brief(timestamp: float, detections: List[Dict]) -> str:\n",
        "    t = format_timestamp(timestamp)\n",
        "    if not detections:\n",
        "        return f\"[{t}] 無偵測結果\"\n",
        "    labels = {}\n",
        "    for d in detections:\n",
        "        lbl = d['label']\n",
        "        sc = d['score']\n",
        "        if lbl not in labels or sc > labels[lbl]:\n",
        "            labels[lbl] = sc\n",
        "    brief = ', '.join(f\"{k}({v:.2f})\" for k, v in sorted(labels.items(), key=lambda x: x[1], reverse=True)[:8])\n",
        "    return f\"[{t}] {brief}\"\n",
        "\n",
        "def create_visualization_summary(detections: List[Dict], max_items: int = 10) -> str:\n",
        "    if not detections:\n",
        "        return \"未偵測到物件\"\n",
        "    items = [f\"{d['label']}({d['score']:.2f})\" for d in detections[:max_items]]\n",
        "    return '、'.join(items)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile scripts/caption_postprocess.py\n",
        "\n",
        "from typing import List, Dict, Any\n",
        "import re\n",
        "import os\n",
        "\n",
        "class CaptionPostProcessor:\n",
        "    def __init__(self, furniture_txt_path: str = \"furniture.txt\", conf_th: float = 0.25):\n",
        "        self.furniture_txt_path = furniture_txt_path\n",
        "        self.conf_th = conf_th\n",
        "\n",
        "        # 會被模型/流程誤印的提示詞（清理用）\n",
        "        self.PROMPT_PREFIXES = [\n",
        "            \"描述環境、物體和在場的任何人\",\n",
        "            \"詳細描述這個室內場景\",\n",
        "            \"詳細描述這一室內場景\",\n",
        "            \"詳細描述這個室內場景, 以人、傢俱和活動為重點\",\n",
        "            \"詳細描述這個室內場景, 以人、傢俱和活動爲重點\",\n",
        "            \"詳細描述這個室內場景, 關注人們、傢俱和活動\",\n",
        "            \"詳細描述這個室內場景, 關注人羣、傢俱和活動\",\n",
        "            \"詳細描述這個室內場景,關注人羣、傢俱和活動\",\n",
        "            \"詳細描述這個室內場景,以人、傢俱和活動爲重點\"\n",
        "        ]\n",
        "\n",
        "        # 英->中 同義詞歸一\n",
        "       self.OBJECT_ALIASES = {\n",
        "            # 家具/家飾\n",
        "            \"desk\": \"桌子\", \"table\": \"桌子\",\n",
        "            \"cabinet\": \"櫥櫃\",\n",
        "            \"chair\": \"椅子\",\n",
        "            \"sofa\": \"沙發\",\n",
        "            \"shelf\": \"書架\", \"bookshelf\": \"書架\",\n",
        "            \"drawer\": \"抽屜\",\n",
        "            \"rug\": \"地墊\",\n",
        "\n",
        "            # 電器\n",
        "            \"refrigerator\": \"冰箱\", \"fridge\": \"冰箱\",\n",
        "            \"oven\": \"烤箱\", \"microwave\": \"微波爐\",\n",
        "            \"tv\": \"螢幕\",\n",
        "            \"coffeemaker\": \"咖啡機\",\n",
        "            \"toaster\": \"烤麵包機\",\n",
        "            \"dishwasher\": \"洗碗機\",\n",
        "            \"washingmachine\": \"洗衣機\",\n",
        "            \"computer\": \"電腦\",\n",
        "            \"printer\": \"印表機\",\n",
        "            \"radio\": \"收音機\", \"speaker\": \"喇叭\",\n",
        "\n",
        "            # 食物/餐具\n",
        "            \"apple\": \"蘋果\", \"bananas\": \"香蕉\", \"bellpepper\": \"甜椒\", \"carrot\": \"胡蘿蔔\",\n",
        "            \"chicken\": \"雞肉\", \"salmon\": \"鮭魚\", \"mincedmeat\": \"絞肉\",\n",
        "            \"breadslice\": \"麵包片\", \"cereal\": \"麥片\", \"crackers\": \"餅乾\",\n",
        "            \"cupcake\": \"杯子蛋糕\", \"pancake\": \"鬆餅\", \"pie\": \"派\", \"pudding\": \"布丁\",\n",
        "            \"milk\": \"牛奶\", \"juice\": \"果汁\", \"wine\": \"紅酒\",\n",
        "            \"bowl\": \"碗\", \"cutleryfork\": \"叉子\", \"cutleryknife\": \"刀子\", \"mug\": \"馬克杯\",\n",
        "            \"plate\": \"盤子\", \"pan\": \"平底鍋\", \"cookingpot\": \"湯鍋\", \"cuttingboard\": \"砧板\",\n",
        "\n",
        "            # 衛浴用品\n",
        "            \"barsoap\": \"肥皂\", \"toothbrush\": \"牙刷\", \"toothpaste\": \"牙膏\",\n",
        "            \"towel\": \"毛巾\", \"towelrack\": \"毛巾架\",\n",
        "            \"deodorant\": \"除臭劑\", \"facecream\": \"護膚霜\", \"hairproduct\": \"美髮產品\",\n",
        "            \"washingsponge\": \"海綿\",\n",
        "\n",
        "            # 其他\n",
        "            \"alcohol\": \"酒精\", \"bottlewater\": \"礦泉水\",\n",
        "            \"book\": \"書\", \"clock\": \"時鐘\",\n",
        "            \"toy\": \"玩具\", \"boardgame\": \"桌遊\",\n",
        "            \"paper\": \"紙\", \"folder\": \"文件夾\",\n",
        "            \"cat\": \"貓\", \"character\": \"角色\", \"person\": \"人\",\n",
        "            \"guitar\": \"吉他\",\n",
        "        }\n",
        "\n",
        "        # 家具集合（輸出到 furniture.txt 的候選）\n",
        "        self.FURNITURE_SET = {\n",
        "            \"桌子\", \"櫥櫃\", \"椅子\", \"沙發\", \"書架\", \"冰箱\", \"烤箱\", \"微波爐\", \"螢幕\", \"床\"\n",
        "        }\n",
        "\n",
        "        # 簡單房型規則\n",
        "        self.ROOM_RULES = [\n",
        "            (\"廚房\", {\"冰箱\", \"烤箱\", \"微波爐\", \"平底鍋\", \"湯鍋\", \"砧板\", \"洗碗機\"}),\n",
        "            (\"臥室\", {\"床\", \"枕頭\", \"書桌\", \"衣櫃\", \"電腦\"}),\n",
        "            (\"客廳\", {\"沙發\", \"螢幕\", \"咖啡機\", \"收音機\", \"喇叭\", \"吉他\"}),\n",
        "            (\"廁所\", {\"肥皂\", \"馬桶\", \"浴缸\", \"毛巾\", \"牙刷\", \"牙膏\"}),\n",
        "        ]\n",
        "\n",
        "        # 預先清空家具檔（每次啟動新流程時）\n",
        "        try:\n",
        "            if os.path.exists(self.furniture_txt_path):\n",
        "                os.remove(self.furniture_txt_path)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # ---------- 公開 API ----------\n",
        "    def process(self, ts_hhmm: str, det_items: List[Dict[str, Any]], raw_caption: str) -> str:\n",
        "        \"\"\"\n",
        "        針對單一時間點輸出一行最終文本（並將家具落到 furniture.txt）\n",
        "        \"\"\"\n",
        "        # 去重 + 依類別整理（中文化）\n",
        "        cats = self._dedupe_by_category(det_items, self.conf_th)\n",
        "\n",
        "        # 家具檔每秒一行\n",
        "        self._append_furniture(ts_hhmm, cats)\n",
        "\n",
        "        # 先用原始敘述清理；若像提示詞或空，合成一句自然語句\n",
        "        caption = self._clean_text(raw_caption or \"\")\n",
        "        if self._looks_like_prompt(caption):\n",
        "            # 資訊來源：是否有人、房型提示、關鍵物件\n",
        "            has_person = self._has_person(cats, caption)\n",
        "            room_hint = self._guess_room(cats)\n",
        "            caption = self._compose_neutral_sentence(room_hint, cats, has_person)\n",
        "\n",
        "        # 物件摘要（去重後、同圖同名只一次）\n",
        "        objects_str = self._format_objects(cats)\n",
        "\n",
        "        # 最終輸出（不含任何提示詞）\n",
        "        line = f\"[{ts_hhmm}] {caption} 偵測到的主要物件包括：{objects_str}。\"\n",
        "        return line\n",
        "\n",
        "    # ---------- 內部工具 ----------\n",
        "    def _zh_label(self, raw_label: str) -> str:\n",
        "        key = (raw_label or \"\").strip().lower()\n",
        "        if key in self.OBJECT_ALIASES:\n",
        "            return self.OBJECT_ALIASES[key]\n",
        "        # 若已是中文或未知詞，直接回傳原詞（去除雜訊）\n",
        "        key = re.sub(r\"[^\\w一-龥]\", \"\", key)\n",
        "        return raw_label if raw_label else \"\"\n",
        "\n",
        "    def _auto_category(self, zh_name: str) -> str:\n",
        "        if zh_name in {\"冰箱\", \"烤箱\", \"微波爐\", \"螢幕\"}:\n",
        "            return \"電器\"\n",
        "        if zh_name in self.FURNITURE_SET:\n",
        "            return \"家具\"\n",
        "        # 其餘歸到其他物件\n",
        "        return \"其他物件\"\n",
        "\n",
        "    def _dedupe_by_category(self, det_items: List[Dict[str, Any]], conf_th: float) -> Dict[str, List[str]]:\n",
        "        out = {\"家具\": set(), \"電器\": set(), \"其他物件\": set()}\n",
        "        for d in det_items or []:\n",
        "            score = float(d.get(\"score\", 0.0) or 0.0)\n",
        "            if score < conf_th:\n",
        "                continue\n",
        "            zh = self._zh_label(str(d.get(\"label\", \"\")))\n",
        "            if not zh:\n",
        "                continue\n",
        "            cat = d.get(\"category\")\n",
        "            if not cat:\n",
        "                cat = self._auto_category(zh)\n",
        "            if cat not in out:\n",
        "                cat = \"其他物件\"\n",
        "            out[cat].add(zh)\n",
        "        return {k: sorted(v) for k, v in out.items() if v}\n",
        "\n",
        "    def _append_furniture(self, ts_hhmm: str, cats: Dict[str, List[str]]) -> None:\n",
        "        furn = [x for x in cats.get(\"家具\", []) if x in self.FURNITURE_SET]\n",
        "        line = f\"[{ts_hhmm}] 家具：\" + (\"、\".join(furn) if furn else \"無\")\n",
        "        try:\n",
        "            with open(self.furniture_txt_path, \"a\", encoding=\"utf-8\") as fp:\n",
        "                fp.write(line + \"\\n\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def _clean_text(self, s: str) -> str:\n",
        "        for p in self.PROMPT_PREFIXES:\n",
        "            s = s.replace(p, \"\")\n",
        "        # 去掉以 ## 開頭的子詞\n",
        "        s = \" \".join([t for t in s.split() if not t.startswith(\"##\")])\n",
        "        # 基本標點清理\n",
        "        s = s.replace(\"，,\", \"，\").replace(\",,\", \",\").replace(\"..\", \".\")\n",
        "        s = s.strip(\" 、。,.；;\")\n",
        "        return s\n",
        "\n",
        "    def _looks_like_prompt(self, s: str) -> bool:\n",
        "        s0 = s.replace(\" \", \"\")\n",
        "        if not s0:\n",
        "            return True\n",
        "        for p in self.PROMPT_PREFIXES:\n",
        "            if s0.startswith(p.replace(\" \", \"\")):\n",
        "                return True\n",
        "        # 全是名詞清單/太短亦視為不合格\n",
        "        if len(s0) < 6:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _has_person(self, cats: Dict[str, List[str]], caption: str) -> bool:\n",
        "        # 以偵測結果或敘述文字初步判斷是否有人\n",
        "        all_words = \"\".join(sum(cats.values(), [])) + caption\n",
        "        return (\"人\" in all_words) or (\"person\" in all_words.lower())\n",
        "\n",
        "    def _guess_room(self, cats: Dict[str, List[str]]) -> str:\n",
        "        bag = set(sum(cats.values(), []))\n",
        "        for room_name, triggers in self.ROOM_RULES:\n",
        "            if bag & triggers:\n",
        "                return room_name\n",
        "        return \"\"  # 不確定就留空（用「在室內」）\n",
        "\n",
        "    def _compose_neutral_sentence(self, room_hint: str, cats: Dict[str, List[str]], has_person: bool) -> str:\n",
        "        room_part = f\"在{room_hint}\" if room_hint else \"在室內\"\n",
        "        furn = \"、\".join(cats.get(\"家具\", [])[:3]) if \"家具\" in cats else \"\"\n",
        "        appl = \"、\".join(cats.get(\"電器\", [])[:2]) if \"電器\" in cats else \"\"\n",
        "        other = \"、\".join(cats.get(\"其他物件\", [])[:2]) if \"其他物件\" in cats else \"\"\n",
        "        obj_part = \"、\".join([x for x in [furn, appl, other] if x])\n",
        "\n",
        "        if has_person:\n",
        "            if obj_part:\n",
        "                return f\"{room_part}可見有人，周圍有{obj_part}。\"\n",
        "            else:\n",
        "                return f\"{room_part}可見有人。\"\n",
        "        else:\n",
        "            if obj_part:\n",
        "                return f\"{room_part}可見{obj_part}。\"\n",
        "            else:\n",
        "                return f\"{room_part}環境整潔，物件稀疏。\"\n",
        "\n",
        "    def _format_objects(self, cats: Dict[str, List[str]]) -> str:\n",
        "        parts = []\n",
        "        for cname in [\"家具\", \"電器\", \"其他物件\"]:\n",
        "            xs = cats.get(cname, [])\n",
        "            if xs:\n",
        "                parts.append(f\"{cname}：\" + \"、\".join(xs))\n",
        "        return \"；\".join(parts) if parts else \"無明顯物件\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmJqE_EcbFZy",
        "outputId": "17ae5e48-1b34-4a74-db37-3d52ebf22527"
      },
      "id": "kmJqE_EcbFZy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing scripts/caption_postprocess.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e0f323f",
      "metadata": {
        "id": "3e0f323f"
      },
      "source": [
        "## 主程式：`main.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45bdc47b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45bdc47b",
        "outputId": "a3a5bd66-1ba1-41a6-ee0e-b52fcb495fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from typing import Iterable\n",
        "from tqdm import tqdm\n",
        "\n",
        "from scripts.extract_frames import extract_frames\n",
        "from scripts.object_detector import setup_grounding_dino, detect_objects, summarize_detections, analyze_scene_context, DEFAULT_PROMPT\n",
        "from scripts.generate_caption import initialize_models, generate_enhanced_caption, infer_room_from_detections\n",
        "from scripts.utils import ensure_dir, save_txt, format_detection_brief, format_timestamp, create_visualization_summary\n",
        "\n",
        "VIDEO_EXTS = {'.mp4', '.mov', '.mkv', '.avi', '.webm'}\n",
        "\n",
        "def iter_videos(targets: Iterable[Path]):\n",
        "    \"\"\"遍歷所有影片檔案\"\"\"\n",
        "    for target in targets:\n",
        "        target = Path(target)\n",
        "        if target.is_file() and target.suffix.lower() in VIDEO_EXTS:\n",
        "            yield target\n",
        "        elif target.is_dir():\n",
        "            for path in sorted(target.rglob('*')):\n",
        "                if path.suffix.lower() in VIDEO_EXTS:\n",
        "                    yield path\n",
        "\n",
        "def process_video(\n",
        "    video_path: Path,\n",
        "    output_root: Path,\n",
        "    fps_sample: float = 1.0,\n",
        "    text_prompt: str = DEFAULT_PROMPT,\n",
        "    show_detection_images: bool = True,\n",
        "    max_preview_images: int = 5\n",
        ") -> Path:\n",
        "    \"\"\"處理單一影片\"\"\"\n",
        "    video_path = Path(video_path)\n",
        "    video_output = ensure_dir(output_root / video_path.stem)\n",
        "    frames_dir = ensure_dir(video_output / 'frames')\n",
        "    detections_dir = ensure_dir(video_output / 'detections')\n",
        "\n",
        "    print(f'\\n=== 開始處理影片：{video_path.name} ===')\n",
        "    print('正在提取影格...')\n",
        "    frame_entries, native_fps = extract_frames(str(video_path), str(frames_dir), target_fps=fps_sample)\n",
        "    if not frame_entries:\n",
        "        raise RuntimeError(f'影片 {video_path} 未擷取到任何影格，請確認檔案是否為有效影片。')\n",
        "    print(f'成功提取 {len(frame_entries)} 個影格，原始FPS: {native_fps:.2f}')\n",
        "\n",
        "    subtitle_lines = []\n",
        "    detection_lines = []\n",
        "    preview_count = 0\n",
        "\n",
        "    for idx, (frame_path, timestamp) in enumerate(tqdm(frame_entries, desc=f'分析 {video_path.name}')):\n",
        "        try:\n",
        "            detections, annotated_image = detect_objects(\n",
        "                frame_path,\n",
        "                text_prompt=text_prompt,\n",
        "                visualize=True\n",
        "            )\n",
        "            if annotated_image is not None:\n",
        "                annotated_path = detections_dir / f'{Path(frame_path).stem}_detection.jpg'\n",
        "                annotated_image.save(annotated_path)\n",
        "                if show_detection_images and preview_count < max_preview_images:\n",
        "                    print(f'\\n第 {idx+1} 個影格偵測結果：')\n",
        "                    vis_summary = create_visualization_summary(detections, len(detections))\n",
        "                    print(vis_summary)\n",
        "                    print(f'高信心度物件：{summarize_detections(detections, top_k=5)}')\n",
        "                    preview_count += 1\n",
        "\n",
        "            scene_context = analyze_scene_context(detections)\n",
        "            room_hint = infer_room_from_detections(detections)\n",
        "\n",
        "            # 重要：字幕只留「純敘述」，關閉所有附加片段\n",
        "            pure_caption = generate_enhanced_caption(\n",
        "                frame_path,\n",
        "                detections,\n",
        "                room_hint=room_hint,\n",
        "                include_objects=False,\n",
        "                include_spatial=False,\n",
        "                include_room=False,\n",
        "                include_knowledge=False,\n",
        "            )\n",
        "            time_str = format_timestamp(timestamp)\n",
        "            subtitle_lines.append(f'[{time_str}] {pure_caption}')\n",
        "\n",
        "            # 偵測摘要（保持原樣，不動）\n",
        "            detection_summary = format_detection_brief(timestamp, detections)\n",
        "            if scene_context['person_count'] > 0:\n",
        "                detection_summary += f' | 人數:{scene_context[\"person_count\"]}'\n",
        "            if room_hint:\n",
        "                detection_summary += f' | 房間:{room_hint}'\n",
        "            detection_lines.append(detection_summary)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f'處理第 {idx+1} 個影格時發生錯誤: {e}')\n",
        "            error_msg = f'[{format_timestamp(timestamp)}] 處理錯誤: {str(e)}'\n",
        "            subtitle_lines.append(error_msg)\n",
        "            detection_lines.append(error_msg)\n",
        "\n",
        "    subs_path = video_output / f'{video_path.stem}_captions.txt'\n",
        "    det_path = video_output / f'{video_path.stem}_detections.txt'\n",
        "    save_txt(subtitle_lines, subs_path)\n",
        "    save_txt(detection_lines, det_path)\n",
        "\n",
        "    report_lines = [\n",
        "        f'影片處理報告 - {video_path.name}',\n",
        "        '=' * 50,\n",
        "        f'原始FPS: {native_fps:.2f}',\n",
        "        f'取樣FPS: {fps_sample}',\n",
        "        f'處理影格數: {len(frame_entries)}',\n",
        "        f'影片總時長: {format_timestamp(frame_entries[-1][1])}' if frame_entries else '無',\n",
        "        f'輸出檔案:',\n",
        "        f'  - 詳細字幕: {subs_path.name}',\n",
        "        f'  - 偵測摘要: {det_path.name}',\n",
        "        f'  - 標註圖像目錄: {detections_dir.name}/',\n",
        "        f'  - 原始影格目錄: {frames_dir.name}/'\n",
        "    ]\n",
        "    report_path = video_output / f'{video_path.stem}_report.txt'\n",
        "    save_txt(report_lines, report_path)\n",
        "\n",
        "    print(f'\\n處理完成！')\n",
        "    print(f'詳細字幕檔: {subs_path}')\n",
        "    print(f'偵測摘要檔: {det_path}')\n",
        "    print(f'處理報告: {report_path}')\n",
        "    print(f'標註圖像: {detections_dir}/')\n",
        "    return subs_path\n",
        "\n",
        "def main() -> None:\n",
        "    \"\"\"主程式入口\"\"\"\n",
        "    parser = argparse.ArgumentParser(description='增強版影片分析系統 - Grounding DINO + BLIP')\n",
        "    parser.add_argument('--video', help='指定單一影片路徑')\n",
        "    parser.add_argument('--dir', help='處理資料夾下的所有影片')\n",
        "    parser.add_argument('--fps', type=float, default=1.0, help='取樣頻率(每秒擷取影格數)')\n",
        "    parser.add_argument('--output-dir', default='outputs', help='輸出根目錄')\n",
        "    parser.add_argument('--prompt', default=DEFAULT_PROMPT, help='物件偵測提示詞')\n",
        "    parser.add_argument('--no-preview', action='store_true', help='不顯示偵測預覽圖像')\n",
        "    parser.add_argument('--max-preview', type=int, default=5, help='最多顯示幾張預覽圖像')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if not args.video and not args.dir:\n",
        "        parser.error('請至少指定 --video 或 --dir 其中之一。')\n",
        "\n",
        "    print('正在初始化模型...')\n",
        "    setup_grounding_dino()\n",
        "    initialize_models()\n",
        "    print('所有模型已準備完成。')\n",
        "\n",
        "    targets = []\n",
        "    if args.video:\n",
        "        targets.append(Path(args.video))\n",
        "    if args.dir:\n",
        "        targets.append(Path(args.dir))\n",
        "    output_root = ensure_dir(args.output_dir)\n",
        "\n",
        "    processed_count = 0\n",
        "    for video in iter_videos(targets):\n",
        "        try:\n",
        "            process_video(\n",
        "                video,\n",
        "                output_root,\n",
        "                fps_sample=args.fps,\n",
        "                text_prompt=args.prompt,\n",
        "                show_detection_images=not args.no_preview,\n",
        "                max_preview_images=args.max_preview\n",
        "            )\n",
        "            processed_count += 1\n",
        "        except Exception as e:\n",
        "            print(f'處理影片 {video} 時發生錯誤: {e}')\n",
        "            continue\n",
        "\n",
        "    print('\\n=== 所有處理完成 ===')\n",
        "    print(f'成功處理 {processed_count} 個影片檔案')\n",
        "    print(f'輸出目錄: {output_root}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cd2d9f2",
      "metadata": {
        "id": "1cd2d9f2"
      },
      "source": [
        "## 執行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce777e89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce777e89",
        "outputId": "291b0ac7-3fa2-47fa-8cdd-fd84c7cd1bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-21 15:45:41.428557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758469541.449776    2472 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758469541.456100    2472 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758469541.471929    2472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758469541.471960    2472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758469541.471963    2472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758469541.471969    2472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-21 15:45:41.476828: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "正在初始化模型...\n",
            "正在載入 Grounding DINO 模型...\n",
            "Fetching 1 files: 100% 1/1 [00:00<00:00, 2685.21it/s]\n",
            "Fetching 1 files: 100% 1/1 [00:00<00:00, 14513.16it/s]\n",
            "Grounding DINO 模型已載入至 cuda\n",
            "正在載入 BLIP 模型...\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Fetching 1 files: 100% 1/1 [00:00<00:00, 3057.07it/s]\n",
            "BLIP 模型已載入至 cuda\n",
            "正在載入翻譯模型...\n",
            "Device set to use cuda:0\n",
            "翻譯模型已載入\n",
            "所有模型已準備完成。\n",
            "\n",
            "=== 開始處理影片：Cook carrot1_1.mp4 ===\n",
            "正在提取影格...\n",
            "已提取 65 個影格，原始FPS: 30.00\n",
            "成功提取 65 個影格，原始FPS: 30.00\n",
            "分析 Cook carrot1_1.mp4:   0% 0/65 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/transformers/models/grounding_dino/processing_grounding_dino.py:94: FutureWarning: The key `labels` is will return integer ids in `GroundingDinoProcessor.post_process_grounded_object_detection` output since v4.51.0. Use `text_labels` instead to retrieve string object names.\n",
            "  warnings.warn(self.message, FutureWarning)\n",
            "\n",
            "第 1 個影格偵測結果：\n",
            "tv monitor(0.39)、table desk table table table desk(0.34)、fork rug(0.32)、cabinet pan(0.25)\n",
            "高信心度物件：tv monitor(0.39), table desk table table table desk(0.34), fork rug(0.32), cabinet pan(0.25)\n",
            "分析 Cook carrot1_1.mp4:   2% 1/65 [00:03<03:26,  3.23s/it]\n",
            "第 2 個影格偵測結果：\n",
            "tv monitor(0.40)、table desk table table table desk(0.34)、sink knife fork rug(0.33)、cabinet(0.25)\n",
            "高信心度物件：tv monitor(0.40), table desk table table table desk(0.34), sink knife fork rug(0.33), cabinet(0.25)\n",
            "分析 Cook carrot1_1.mp4:   3% 2/65 [00:05<02:42,  2.58s/it]\n",
            "第 3 個影格偵測結果：\n",
            "tv monitor(0.39)、sink knife fork rug(0.33)、table desk table table table desk(0.32)、cabinet(0.26)\n",
            "高信心度物件：tv monitor(0.39), sink knife fork rug(0.33), table desk table table table desk(0.32), cabinet(0.26)\n",
            "分析 Cook carrot1_1.mp4:   5% 3/65 [00:07<02:15,  2.18s/it]\n",
            "第 4 個影格偵測結果：\n",
            "tv monitor(0.38)、sink knife fork rug(0.33)、table desk table table table desk(0.32)、cabinet(0.26)\n",
            "高信心度物件：tv monitor(0.38), sink knife fork rug(0.33), table desk table table table desk(0.32), cabinet(0.26)\n",
            "分析 Cook carrot1_1.mp4:   6% 4/65 [00:08<02:02,  2.01s/it]\n",
            "第 5 個影格偵測結果：\n",
            "chair chair chair(0.43)\n",
            "高信心度物件：chair chair chair(0.43)\n",
            "分析 Cook carrot1_1.mp4:  15% 10/65 [00:18<01:32,  1.68s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "分析 Cook carrot1_1.mp4: 100% 65/65 [01:52<00:00,  1.73s/it]\n",
            "\n",
            "處理完成！\n",
            "詳細字幕檔: outputs/Cook carrot1_1/Cook carrot1_1_captions.txt\n",
            "偵測摘要檔: outputs/Cook carrot1_1/Cook carrot1_1_detections.txt\n",
            "處理報告: outputs/Cook carrot1_1/Cook carrot1_1_report.txt\n",
            "標註圖像: outputs/Cook carrot1_1/detections/\n",
            "\n",
            "=== 開始處理影片：Cook fried bread4_1.mp4 ===\n",
            "正在提取影格...\n",
            "已提取 65 個影格，原始FPS: 30.00\n",
            "成功提取 65 個影格，原始FPS: 30.00\n",
            "分析 Cook fried bread4_1.mp4:   0% 0/65 [00:00<?, ?it/s]\n",
            "第 1 個影格偵測結果：\n",
            "chair chair chair(0.38)、desk desk(0.27)\n",
            "高信心度物件：chair chair chair(0.38), desk desk(0.27)\n",
            "分析 Cook fried bread4_1.mp4:   2% 1/65 [00:01<01:41,  1.59s/it]\n",
            "第 2 個影格偵測結果：\n",
            "desk desk(0.27)\n",
            "高信心度物件：desk desk(0.27)\n",
            "分析 Cook fried bread4_1.mp4:   3% 2/65 [00:03<01:38,  1.56s/it]\n",
            "第 3 個影格偵測結果：\n",
            "chair chair chair(0.42)、desk desk(0.27)\n",
            "高信心度物件：chair chair chair(0.42), desk desk(0.27)\n",
            "分析 Cook fried bread4_1.mp4:   5% 3/65 [00:04<01:37,  1.58s/it]\n",
            "第 4 個影格偵測結果：\n",
            "chair chair chair(0.42)、desk desk(0.26)\n",
            "高信心度物件：chair chair chair(0.42), desk desk(0.26)\n",
            "分析 Cook fried bread4_1.mp4:   6% 4/65 [00:06<01:41,  1.66s/it]\n",
            "第 5 個影格偵測結果：\n",
            "chair chair chair(0.42)\n",
            "高信心度物件：chair chair chair(0.42)\n",
            "分析 Cook fried bread4_1.mp4: 100% 65/65 [01:53<00:00,  1.75s/it]\n",
            "\n",
            "處理完成！\n",
            "詳細字幕檔: outputs/Cook fried bread4_1/Cook fried bread4_1_captions.txt\n",
            "偵測摘要檔: outputs/Cook fried bread4_1/Cook fried bread4_1_detections.txt\n",
            "處理報告: outputs/Cook fried bread4_1/Cook fried bread4_1_report.txt\n",
            "標註圖像: outputs/Cook fried bread4_1/detections/\n",
            "\n",
            "=== 開始處理影片：Cook potato using microwave1_4.mp4 ===\n",
            "正在提取影格...\n",
            "已提取 76 個影格，原始FPS: 30.00\n",
            "成功提取 76 個影格，原始FPS: 30.00\n",
            "分析 Cook potato using microwave1_4.mp4:   0% 0/76 [00:00<?, ?it/s]\n",
            "第 1 個影格偵測結果：\n",
            "chair chair chair(0.36)、table table table table(0.29)、rug(0.27)、cabinet(0.27)\n",
            "高信心度物件：chair chair chair(0.36), table table table table(0.29), rug(0.27), cabinet(0.27)\n",
            "分析 Cook potato using microwave1_4.mp4:   1% 1/76 [00:01<02:00,  1.61s/it]\n",
            "第 2 個影格偵測結果：\n",
            "chair chair chair(0.37)、fork rug(0.29)、table table table table(0.29)、cabinet(0.29)、desk desk(0.29)、monitor(0.27)\n",
            "高信心度物件：chair chair chair(0.37), fork rug(0.29), table table table table(0.29), cabinet(0.29), desk desk(0.29)\n",
            "分析 Cook potato using microwave1_4.mp4:  16% 12/76 [00:20<01:37,  1.52s/it]\n",
            "第 13 個影格偵測結果：\n",
            "table table table table(0.26)\n",
            "高信心度物件：table table table table(0.26)\n",
            "分析 Cook potato using microwave1_4.mp4:  17% 13/76 [00:21<01:35,  1.52s/it]\n",
            "第 14 個影格偵測結果：\n",
            "table table table table(0.25)\n",
            "高信心度物件：table table table table(0.25)\n",
            "分析 Cook potato using microwave1_4.mp4: 100% 76/76 [02:08<00:00,  1.69s/it]\n",
            "\n",
            "處理完成！\n",
            "詳細字幕檔: outputs/Cook potato using microwave1_4/Cook potato using microwave1_4_captions.txt\n",
            "偵測摘要檔: outputs/Cook potato using microwave1_4/Cook potato using microwave1_4_detections.txt\n",
            "處理報告: outputs/Cook potato using microwave1_4/Cook potato using microwave1_4_report.txt\n",
            "標註圖像: outputs/Cook potato using microwave1_4/detections/\n",
            "\n",
            "=== 所有處理完成 ===\n",
            "成功處理 3 個影片檔案\n",
            "輸出目錄: outputs\n"
          ]
        }
      ],
      "source": [
        "# 單支影片\n",
        "# !python main.py --video data/videos/你的影片.mp4 --fps 2 --output-dir outputs\n",
        "\n",
        "# 批次處理資料夾\n",
        "!python main.py --dir data/videos --fps 1 --output-dir outputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as display\n",
        "\n",
        "# 執行完這段會呼叫前端 JS，讓 Colab 斷線\n",
        "# display.display(display.Javascript('google.colab.kernel.disconnect()'))\n"
      ],
      "metadata": {
        "id": "hWTLmq-ly1s8"
      },
      "id": "hWTLmq-ly1s8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "51ecce7a",
      "metadata": {
        "id": "51ecce7a"
      },
      "source": [
        "## 可調參數與修改位置導覽（完整標示）\n",
        "- 修改偵測提示詞：`main.py` 的 `--prompt` 參數或 `scripts/object_detector.py` 的 `DEFAULT_PROMPT`。\n",
        "- 偵測信心閾值與回傳數量：`scripts/object_detector.py` 的 `detect_objects(..., box_threshold=0.25, top_k=15)`。\n",
        "- 影格取樣頻率：執行參數 `--fps`；或在 `scripts/extract_frames.py` 的 `target_fps` 預設值。\n",
        "- 翻譯與中文轉換：`scripts/generate_caption.py` 的 `initialize_models()` 使用 `Helsinki-NLP/opus-mt-en-zh` 及 `OpenCC('s2t')`。\n",
        "- 房間推斷關鍵詞：`scripts/generate_caption.py` 中的 `ROOM_KEYWORDS` 字典。\n",
        "- 環境描述模板：`scripts/generate_caption.py` 的 `ENVIRONMENT_TEMPLATES`。\n",
        "- 物件中英對照：`scripts/generate_caption.py` 的 `OBJECT_TRANSLATIONS`。\n",
        "- 文字輸出檔名與摘要邏輯：`scripts/utils.py` 的 `save_txt`, `format_detection_brief`, `format_timestamp`。\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}